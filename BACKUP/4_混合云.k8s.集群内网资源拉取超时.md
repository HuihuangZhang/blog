# [混合云 k8s 集群内网资源拉取超时](https://github.com/HuihuangZhang/blog/issues/4)


# 1. 背景

dev 环境的 k8s 集群有 3 台机器：

- 192.168.1.130 (dev-master)
   - Control-plane，master 节点
   - 云A
- 192.168.1.131 (dev-worker)
   - Worker
   - 云A
- 10.119.96.10 (044c82ef-1f4a-11f0-b290-7ea3ea26affc)
   - Worker w/ GPU
   - 云B

云 A 和云 B 之间是通过 SD-WAN 方案来打通的。机器之间可以相互 ping 通。
k8s 集群版本为 v1.95.5
集群使用 `coredns` 作为集群的 DNS server。
在 GPU 机器上部署一个模型服务，服务名称为：`mos-model`。

# 2. 问题
## 2.1. 定位过程

表现上，`mos-model` 服务在启动时会使用 `aws` 命令拉取 云B 上的 S3 存储资源。在拉取资源时，日志显示请求阻塞，并在 5min 后超时（部署配置）容器被重启。

> 拉取的完整命令是：`aws --endpoint-url=<ENDPOINT> s3 cp s3://<REMOTE-PATH> <LOCAL-PATH> --recursive`。
> 需要额外 `export AWS_ACCESS_KEY_ID` 和 `export AWS_SECRET_ACCESS_KEY` 变量，这是 `aws` 命令依赖的。 

另外在 gpu 节点上部署一个镜像为 `ubuntu:2204` 的容器，用来 debug 该 `aws` 命令。单独运行该命令，出现了 `mos-model` 服务中的表现，一直卡住。在原命令的基础上，加上 `--debug` 用来输出更多信息，完整的信息见：[aws.log](https://github.com/HuihuangZhang/blog/blob/master/notes/issue4/aws.log)

看不出什么有用的信息。

尝试在 debug 容器上用 `telnet <ENDPOINT> 80` 命令查看解析到的 IP 地址，显示为 `10.118.163.249`，但 `telnet` 命令运行失败。运行 `ping 10.118.119.245` 仍然失败。

尝试在宿主机上运行 `telnet <ENDPOINT> 80` 命令，解析出来的地址为 `10.118.119.245`，并且 `telnet` 命令运行成功。

通过查看官方文档，`10.118.119.245` 是云 B VPC 内网的访问地址，通过在宿主机上成功运行命令可以证实内网可访问。

通过在云 B VPC 外的机器上运行 `telnet <ENDPOINT> 80`，同样可以解析出 `10.118.163.249` 的 IP 地址。

> [!NOTE]
> 从表现上看，即使容器在云 B VPC 内，但访问到的地址仍然和外网解析到的地址一样。

查看 debug 容器的 `/etc/resolv.conf`：

```
search mos.svc.cluster.local svc.cluster.local cluster.local
nameserver 10.96.0.10
options ndots:5
```

没有额外的配置。运行 `kubectl describe cm coredns -n kube-system` 查看 coredns 的 ConfigMap：

```
.:53 {
    errors
    health {
       lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    cache 30
    loop
    reload
    loadbalance
}
```

从 ConfigMap 上看，如果 pod 解析不到，会转发到宿主机来做解析。

进一步思考，从表现上，说明该 dns 解析不发生在云 B 的机器上，如果在云 B 的机器上，那解析出来的应该是内网 IP。由此推测 dns 解析没有发生在 云 B 的机器上。运行 `kubectl get pod -n kube-system -l k8s-app=kube-dns -o wide` 命令：

```
NAME                       READY   STATUS    RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES
coredns-7dbc744b8d-5svcg   1/1     Running   0          20d   10.245.1.33   dev-worker   <none>           <none>
coredns-7dbc744b8d-8n48p   1/1     Running   0          39d   10.245.0.7    dev-master   <none>           <none>
```

从结果看，`coredns` pod 运行在云 A 的机器上，而 S3 存储是在云 B 上的。

> [!IMPORTANT]
> 那现象就可以解释通了，根因是：云 B 上的 pod 运行 `aws --endpoint=<ENDPOINT>` 时，在集群内的 dnscore 解析不到 `<ENDPOINT>` 这个地址，所以 forward 到上游宿主机进行 dns 解析，因为宿主机不在云 B 里，所以解析出来一个公网的地址，导致该地址访问不了。

# 3. 解决办法

一开始想，如果 `coredns` 会 forward 到上游来解析，那是不是确保有一个 `coredns` 实例在云 B，并且确保云 B 的 pod 都通过该实例进行 dns 解析就可以。但查了一下，k8s 并不保证节点上的 pod 一定会在该节点上的 `coredns` 实例进行 dns 解析。最简单的解决方案是修改 `coredns` ConfigMap，将 `<ENDPOINT>` 的解析地址显式地写入配置中。

运行 `kubectl edit cm coredns -n kube-system`，添加 `hosts` 配置，

```
.:53 {
    # ...
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    hosts {
        10.118.119.245 <ENDPOINT>
        fallthrough  # 允许未匹配的域名继续向下解析
    }
    cache 30
    loop
    reload
    loadbalance
}
```

因为 ConfigMap 中有 `reload` 插件，所以无需重启 pod。

再次进入 debug 容器，运行 `telnet <ENDPOINT> 80`，运行成功！问题解决！

> [!WARNING]
> 这个解决办法仍然有隐患，需要确保访问特定云内网域名/IP 的服务在特定的云环境上，不然仍然会出现问题。例如云 A 上的 pod 通过 coredns 解析到云 B 上的内网 IP，访问仍然会有问题。所以需要对 pod 的调度做约束，复杂度更高了！