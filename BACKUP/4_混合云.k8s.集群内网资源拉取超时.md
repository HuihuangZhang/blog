# [混合云 k8s 集群内网资源拉取超时](https://github.com/HuihuangZhang/blog/issues/4)


# 1. 背景

dev 环境的 k8s 集群有 3 台机器：

- 192.168.1.130 (dev-master)
   - Control-plane，master 节点
   - 云A
- 192.168.1.131 (dev-worker)
   - Worker
   - 云A
- 10.119.96.10 (044c82ef-1f4a-11f0-b290-xxxx)
   - Worker w/ GPU
   - 云B - zone1
- 10.119.96.11 (044c82ef-1f4a-11f0-b290-yyyy)
   - Worker w/ GPU
   - 云B - zone2

云 A 和云 B 之间是通过 SD-WAN 方案来打通的。机器之间可以相互 ping 通。
k8s 集群版本为 v1.95.5
集群使用 `coredns` 作为集群的 DNS server。
在 GPU 机器上部署一个模型服务，服务名称为：`mos-model`。

# 2. 问题
## 2.1. 拉取 S3 存储超时

表现上，`mos-model` 服务被分配到了 云B zone1 上，在启动时会使用 `aws` 命令拉取 云B 上的 S3 存储资源。在拉取资源时，日志显示请求阻塞，并在 5min 后超时（部署配置）容器被重启。

> 拉取的完整命令是：`aws --endpoint-url=<ENDPOINT> s3 cp s3://<REMOTE-PATH> <LOCAL-PATH> --recursive`。
> 需要额外 `export AWS_ACCESS_KEY_ID` 和 `export AWS_SECRET_ACCESS_KEY` 变量，这是 `aws` 命令依赖的。 

另外在 gpu 节点上部署一个镜像为 `ubuntu:2204` 的容器，用来 debug 该 `aws` 命令。单独运行该命令，出现了 `mos-model` 服务中的表现，一直卡住。在原命令的基础上，加上 `--debug` 用来输出更多信息，完整的信息见：[aws.log](https://github.com/HuihuangZhang/blog/blob/master/notes/issue4/aws.log)

看不出什么有用的信息。

尝试在 debug 容器上用 `dig <ENDPOINT>` 命令查看 IP 地址列表，显示了多个地址。

尝试在 debug 容器上用 `telnet 10.118.119.245 80` 命令， `telnet` 命令运行失败。运行 `ping 10.118.119.245` 仍然失败。

尝试在宿主机上运行 `telnet <ENDPOINT> 80` 命令，解析出来的地址为 `10.118.119.245`，并且 `telnet` 命令运行成功。

通过查看官方文档，`10.118.119.245` 是云 B VPC 内网的访问地址，通过在宿主机上成功运行命令可以证实内网可访问。

通过在云 B VPC 外的机器上运行 `telnet <ENDPOINT> 80`，同样可以解析出 `10.118.163.249` 的 IP 地址。

> [!NOTE]
> 从表现上看，即使容器在云 B VPC 内，但访问到的地址仍然和外网解析到的地址一样。

查看 debug 容器的 `/etc/resolv.conf`：

```
search mos.svc.cluster.local svc.cluster.local cluster.local
nameserver 10.96.0.10
options ndots:5
```

没有额外的配置。运行 `kubectl describe cm coredns -n kube-system` 查看 coredns 的 ConfigMap：

```
.:53 {
    errors
    health {
       lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    cache 30
    loop
    reload
    loadbalance
}
```

从 ConfigMap 上看，如果 pod 解析不到，会转发到宿主机来做解析。

进一步思考，从表现上，说明该 dns 解析不发生在云 B 的机器上，如果在云 B 的机器上，那解析出来的应该是内网 IP。由此推测 dns 解析没有发生在 云 B 的机器上。运行 `kubectl get pod -n kube-system -l k8s-app=kube-dns -o wide` 命令：

```
NAME                       READY   STATUS    RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES
coredns-7dbc744b8d-5svcg   1/1     Running   0          20d   10.245.1.33   dev-worker   <none>           <none>
coredns-7dbc744b8d-8n48p   1/1     Running   0          39d   10.245.0.7    dev-master   <none>           <none>
```

从结果看，`coredns` pod 运行在云 A 的机器上，而 S3 存储是在云 B 上的。

> [!IMPORTANT]
> 那现象就可以解释通了，根因是：云 B 上的 pod 运行 `aws --endpoint=<ENDPOINT>` 时，在集群内的 dnscore 解析不到 `<ENDPOINT>` 这个地址，所以 forward 到上游宿主机进行 dns 解析，因为宿主机不在云 B 里，所以解析出来一个公网的地址，导致该地址访问不了。

### 解决办法：修改全局 hosts 配置

一开始想，如果 `coredns` 会 forward 到上游来解析，那是不是确保有一个 `coredns` 实例在云 B，并且确保云 B 的 pod 都通过该实例进行 dns 解析就可以。但查了一下，k8s 并不保证节点上的 pod 一定会在该节点上的 `coredns` 实例进行 dns 解析。最简单的解决方案是修改 `coredns` ConfigMap，将 `<ENDPOINT>` 的解析地址显式地写入配置中。

运行 `kubectl edit cm coredns -n kube-system`，添加 `hosts` 配置，

```
.:53 {
    # ...
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    hosts {
        10.118.163.242 <ENDPOINT>
        10.118.163.243 <ENDPOINT>
        fallthrough  # 允许未匹配的域名继续向下解析
    }
    cache 30
    loop
    reload
    loadbalance
}
```

因为 ConfigMap 中有 `reload` 插件，所以无需重启 pod。

再次进入 debug 容器，运行 `telnet <ENDPOINT> 80`，可以成功运行。

> [!WARNING]
> 这个解决办法仍然有隐患，需要确保访问特定云内网域名/IP 的服务在特定的云环境上，不然仍然会出现问题。例如云 A 上的 pod 通过 coredns 解析到云 B 上的内网 IP，访问仍然会有问题。所以需要对 pod 的调度做约束！

## 2.2. zone2 服务访问 S3 存储超时

在 云B zone2 中，部署了另一个服务 service B，其中 service B 中也有 `aws --endpoint-url=<ENDPOINT> s3 cp xxx` 拉取数据，在拉取数据时，出现超时的错误。

在 service B 的宿主机上（云B zone2），用 `aws --endpoint-url=<ENDPOINT> s3 cp xxx` 可以正常拉取数据。在宿主机上，运行 `dig <ENDPOINT>`，得到 `[10.118.119.244, 10.118.119.245]` 的 IP 列表。

在 2.1. 配置后，在 service B 中运行 `dig <ENDPOINT>`，得到 `[10.118.163.242, 10.118.163.243]` 的 IP 列表，该结果符合 coredns 的 corefile 配置的结果。在容器内使用 `telnet 10.118.163.242` 命令，发现不通。

但通过了解后得知，在 zone1 和 zone2 上解析得到的 IP 列表不同：

- 云B zone1：`[10.118.163.242, 10.118.163.243]`
- 云B zone2：`[10.118.119.244, 10.118.119.245]`

两个 zone 之间的网络不互通。这时候简单通过 coredns 的 hosts 配置以及不能满足需求了。

### 解决办法1：通过给 zone2 的每个 pod 写入 `hostAliases` 配置

在 `Deployment` 的配置中，写入：

```
# ...
spec:
  # ...
  template:
    #...
    spec:
      serviceAccountName: default
      hostAliases:
        - ip: "10.118.119.244"
          hostnames:
          - "<ENDPOINT>"
        - ip: "10.118.119.245"
          hostnames:
          - "<ENDPOINT>"
      containers:
        - name: service-b
          image: "service-b:{{ .Values.image.tag }}"
          imagePullPolicy: IfNotPresent
          ports:
# ...
```

`hostAliases` 可以将对应的 dns 解析规则放进 pod 的 `/etc/hosts` 文件中，就可以在单个 pod 维度上生效。


### 解决方法2：通过 coredns view plugin 配置

通过 coredns 的 `view` 插件 [^1][^2]。运行 `kubectl describe node <NODE>` 查看在 zone2 的节点的 CIDR（在这里是 `10.245.5.0/24`）。通过配置 zone2 的 view，按照规则，指定特定的 CIDR，让对应的 DNS 解析规则在 zone2 的 pod 上生效。


```
. {
    view zone2 {
        expr incidr(client_ip(), '10.245.5.0/24')
    }
    hosts {
        10.118.163.242 <ENDPOINT>
        10.118.163.243 <ENDPOINT>

        fallthrough
    }

    # Include the essential plugins from your original configuration.
    errors
    health {
        lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
        pods insecure
        fallthrough in-addr.arpa ip6.arpa
        ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
        max_concurrent 1000
    }
    cache 30
    loop
    reload
    loadbalance
}

.:53 {
    # ...
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    hosts {
        10.118.119.244 <ENDPOINT>
        10.118.119.245 <ENDPOINT>

        fallthrough  # 允许未匹配的域名继续向下解析
    }
    cache 30
    loop
    reload
    loadbalance
}
```

### 总结

上述的两个方法都能解决问题，配置的粒度不同。在目前的问题场景下，方法 1 解决起来更复杂一些。


[^1]: https://coredns.io/plugins/view/
[^2]: https://github.com/coredns/coredns/tree/master/plugin/view